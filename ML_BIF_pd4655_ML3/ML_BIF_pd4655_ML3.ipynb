{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad1d2a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:32: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:32: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\Paulina\\AppData\\Local\\Temp\\ipykernel_22864\\282008108.py:32: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  print(\"\\TEST 1 – 25% test, (6,3) neurony, relu, 1000 iteracji\")\n",
      "c:\\Users\\Paulina\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Paulina\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\TEST 1 – 25% test, (6,3) neurony, relu, 1000 iteracji\n",
      "Accuracy: 0.6\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n",
      "\n",
      "TEST 2 – 40% test, (12,6) neurony, tanh, 1500 iteracji\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, classification_report\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Dane\n",
    "data = {\n",
    "    'TP53_expr': [2.1, 8.5, 1.8, 6.2, 7.9, 3.1, 9.2, 2.8, 6.8, 4.3, 7.5, 3.6, 5.2, 8.1, 1.9, 3.7, 5.9, 2.2, 6.5, 7.8],\n",
    "    'BRCA1_expr': [3.4, 7.2, 2.5, 6.1, 6.8, 4.0, 7.9, 3.9, 6.6, 4.2, 7.0, 4.1, 5.8, 7.3, 2.2, 3.8, 5.5, 3.0, 6.0, 7.1],\n",
    "    'TF_motifs': [2, 6, 1, 4, 5, 2, 6, 3, 5, 3, 5, 2, 3, 6, 1, 3, 4, 2, 5, 5],\n",
    "    'MYC_expr': [1.5, 4.8, 1.2, 3.9, 5.1, 2.0, 4.9, 1.8, 3.8, 2.4, 4.5, 2.2, 3.1, 4.7, 1.3, 2.5, 3.7, 1.6, 4.1, 5.0],\n",
    "    'CDKN2A_expr': [0.8, 2.3, 0.6, 1.7, 2.5, 1.0, 2.4, 0.9, 1.8, 1.2, 2.1, 1.1, 1.6, 2.2, 0.7, 1.3, 1.9, 0.8, 2.0, 2.6],\n",
    "    'Promoter_methylation': [70, 20, 85, 30, 25, 65, 15, 75, 35, 60, 18, 55, 40, 22, 80, 58, 33, 68, 28, 19],\n",
    "    'Chromatin_accessibility': [0.35, 0.92, 0.25, 0.78, 0.89, 0.42, 0.94, 0.31, 0.74, 0.45, 0.90, 0.50, 0.63, 0.91, 0.22, 0.47, 0.70, 0.38, 0.81, 0.93],\n",
    "    'Cancer_status': [0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "X = df.drop(columns='Cancer_status')\n",
    "y = df['Cancer_status']\n",
    "\n",
    "# test1\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "mlp1 = MLPClassifier(hidden_layer_sizes=(6, 3), activation='relu', max_iter=1000, random_state=42)\n",
    "mlp1.fit(X_train1, y_train1)\n",
    "y_pred1 = mlp1.predict(X_test1)\n",
    "\n",
    "print(\"\\TEST 1 – 25% test, (6,3) neurony, relu, 1000 iteracji\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test1, y_pred1), 2))\n",
    "print(\"Precision:\", round(precision_score(y_test1, y_pred1), 2))\n",
    "print(\"Recall:\", round(recall_score(y_test1, y_pred1), 2))\n",
    "print(\"F1 Score:\", round(f1_score(y_test1, y_pred1), 2))\n",
    "print()\n",
    "\n",
    "# test2\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.4, random_state=7)\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(12, 6), activation='tanh', max_iter=1500, random_state=7)\n",
    "mlp2.fit(X_train2, y_train2)\n",
    "y_pred2 = mlp2.predict(X_test2)\n",
    "\n",
    "print(\"TEST 2 – 40% test, (12,6) neurony, tanh, 1500 iteracji\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test2, y_pred2), 2))\n",
    "print(\"Precision:\", round(precision_score(y_test2, y_pred2), 2))\n",
    "print(\"Recall:\", round(recall_score(y_test2, y_pred2), 2))\n",
    "print(\"F1 Score:\", round(f1_score(y_test2, y_pred2), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c99ad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Komentarz do wynikow\n",
    "#Test 1 model z mala liczba neuronow i funkcja aktywacji relu osiagnal bardzo slaby wynik gdzie dokladnosc wynosi tylko 60%, a wszystkie pozostale metryki wyniosly 0\n",
    "#moze to zonaczac ze model przewidywał tylko jedna jedna klase (\"0\"-zdrowi) costanowi duzy blad w przypadku klasyfikacji chorob\n",
    "\n",
    "#Test 2 zasotosowanie wiekszej liczby neuronow, funckji tanh i dluzszego treningu (1500 iteracji) doprowadzilo do perfekcyjnego wyniku (accuracy, precision, recall, f1=1.0 )\n",
    "# Pokazuje to ze odpowiednia konfiguracja sieci neuronowej ma ogromny wplyw na jej skutecznosc \n",
    "\n",
    "#Bardzo idealne wyniki na malym zbiorze moge oznacza overfitting. Zalecałoby się wiec dodatkowa walidacje lub wiekszyz sestaw danych"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
